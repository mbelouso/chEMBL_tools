{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4171d75b",
   "metadata": {},
   "source": [
    "Notebook for chEMBL Database curation and generation of a diverset set of small molecule for structure in BOLTZ2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c5c897",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem import Fingerprints\n",
    "import pandas as pd\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans\n",
    "import sys\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from molbloom import buy\n",
    "import os\n",
    "from typing import Optional, Tuple\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd10927f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the database location and UNIPROT mappings\n",
    "db_location = 'chembl_36/chembl_36_sqlite/chembl_36.db'\n",
    "uniprot_mapping = 'chembl_uniprot_mapping.txt'\n",
    "\n",
    "# Default location of the ChEMBL database file\n",
    "DEFAULT_DB_FILENAME = \"chembl_36/chembl_36_sqlite/chembl_36.db\"\n",
    "\n",
    "# Load the UNIPROT mappings\n",
    "uniprot_df = pd.read_csv(uniprot_mapping, sep='\\t')\n",
    "print(\"UNIPROT mappings loaded:\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf105ff",
   "metadata": {},
   "source": [
    "Edit Cell below for different filtering options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9e3337",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################\n",
    "# Query for drug-like molecules (Lipinski-like)\n",
    "# Edit the values below to change the query parameters\n",
    "mw_range = (500, 900)  # MW between 200-500\n",
    "logp_range = (3, 5)    # LogP between 0-5\n",
    "purchasable_only = True  # Only include purchasable compounds\n",
    "create_random = True\n",
    "random_subset_amount = 200\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab75f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Functions for querying the database\n",
    "\n",
    "def get_property_query() -> str:\n",
    "    \"\"\"Returns the SQL query to fetch compounds based on molecular weight and LogP.\"\"\"\n",
    "    sql = \"\"\"SELECT\n",
    "        cs.molregno,\n",
    "        cs.canonical_smiles,\n",
    "        cp.mw_freebase as molecular_weight,\n",
    "        cp.alogp,\n",
    "        cp.hba,\n",
    "        cp.hbd,\n",
    "        cp.psa,\n",
    "        cp.rtb,\n",
    "        cp.num_ro5_violations,\n",
    "        md.chembl_id\n",
    "    FROM\n",
    "        compound_structures cs\n",
    "            JOIN\n",
    "        compound_properties cp ON cs.molregno = cp.molregno\n",
    "            JOIN\n",
    "        molecule_dictionary md ON cs.molregno = md.molregno\n",
    "    WHERE\n",
    "        cp.mw_freebase BETWEEN ? AND ?\n",
    "        AND cp.alogp BETWEEN ? AND ?\n",
    "        AND cs.canonical_smiles IS NOT NULL;\"\"\"\n",
    "    return sql\n",
    "\n",
    "def query_by_properties(\n",
    "    mw_range: Tuple[float, float],\n",
    "    logp_range: Tuple[float, float],\n",
    "    db_filename: str = DEFAULT_DB_FILENAME\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Query ChEMBL database for compounds within specified MW and LogP ranges.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    mw_range : tuple of (min_mw, max_mw)\n",
    "        Molecular weight range\n",
    "    logp_range : tuple of (min_logp, max_logp)\n",
    "        LogP range\n",
    "    db_filename : str\n",
    "        Path to ChEMBL database file\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        DataFrame containing compounds matching the criteria\n",
    "    \"\"\"\n",
    "    if not os.path.exists(db_filename):\n",
    "        print(f\"Error: Can't find ChEMBL database file {db_filename}\", file=sys.stderr)\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    min_mw, max_mw = mw_range\n",
    "    min_logp, max_logp = logp_range\n",
    "\n",
    "    print(f\"Querying compounds with MW: {min_mw}-{max_mw}, LogP: {min_logp}-{max_logp}\")\n",
    "\n",
    "    try:\n",
    "        conn = sqlite3.connect(db_filename)\n",
    "        sql = get_property_query()\n",
    "        df = pd.read_sql_query(sql, conn, params=(min_mw, max_mw, min_logp, max_logp))\n",
    "        conn.close()\n",
    "    except sqlite3.Error as e:\n",
    "        print(f\"Database error: {e}\", file=sys.stderr)\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    print(f\"Found {len(df)} compounds matching criteria\")\n",
    "    return df\n",
    "\n",
    "def add_purchasability(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Add purchasability information to the DataFrame using MolBloom.\n",
    "    \"\"\"\n",
    "    if df.empty:\n",
    "        return df\n",
    "    \n",
    "    print(\"Checking for purchasable compounds...\")\n",
    "    df['purchasable'] = [buy(smi, canonicalize=True) for smi in tqdm(df.canonical_smiles)]\n",
    "    print(f\"{df['purchasable'].sum()} of {len(df)} compounds are purchasable\")\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "# Check to see if there is a is a pkl file already, if so, load it, if not run the query_by_properties function\n",
    "pkl_file = f\"compounds_MW{mw_range[0]}-{mw_range[1]}_LogP{logp_range[0]}-{logp_range[1]}.pkl\"\n",
    "\n",
    "if os.path.exists(pkl_file):\n",
    "    df_compounds = pd.read_pickle(pkl_file)\n",
    "    print(f\"Loaded DataFrame from {pkl_file}\")\n",
    "else:\n",
    "    df_compounds = query_by_properties(mw_range, logp_range, db_filename=db_location)\n",
    "\n",
    "# Write df_compounds to a .pkl file\n",
    "\n",
    "if not df_compounds.empty:\n",
    "    pkl_file = f\"compounds_MW{mw_range[0]}-{mw_range[1]}_LogP{logp_range[0]}-{logp_range[1]}.pkl\"\n",
    "    df_compounds.to_pickle(pkl_file)\n",
    "    print(f\"DataFrame saved to {pkl_file}\")\n",
    "\n",
    "\n",
    "# Display summary statistics\n",
    "if not df_compounds.empty:\n",
    "    print(\"\\n=== Summary Statistics ===\")\n",
    "    print(df_compounds[['molecular_weight', 'alogp', 'hba', 'hbd', 'psa']].describe())\n",
    "    \n",
    "    print(\"\\n=== Sample compounds ===\")\n",
    "    print(df_compounds.head(10))\n",
    "    \n",
    "    # Optionally add purchasability check (this may take a while for large datasets)\n",
    "    # use conditional check to see if purchasability column already exists\n",
    "    if 'purchasable' not in df_compounds.columns:\n",
    "        df_compounds = add_purchasability(df_compounds)\n",
    "    \n",
    "    if purchasable_only:\n",
    "        df_compounds = df_compounds[df_compounds['purchasable']]\n",
    "        print(f\"\\nFiltered to {len(df_compounds)} purchasable compounds.\")\n",
    "    # Save to CSV\n",
    "    output_file = f\"compounds_MW{mw_range[0]}-{mw_range[1]}_LogP{logp_range[0]}-{logp_range[1]}.csv\"\n",
    "    df_compounds.to_csv(output_file, index=False)\n",
    "    df_compounds.to_pickle(pkl_file)\n",
    "\n",
    "    print(f\"\\nResults saved to {output_file}\")\n",
    "    print(f\"DataFrame saved to {pkl_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6700c57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the smiles strings and convert them to RDKit molecules and generate fingerprints\n",
    "if not df_compounds.empty:\n",
    "    if 'rdkit_mol' not in df_compounds.columns or 'fingerprint' not in df_compounds.columns:\n",
    "        print(\"\\nGenerating RDKit molecules and fingerprints...\")\n",
    "    \n",
    "        df_compounds['rdkit_mol'] = df_compounds['canonical_smiles'].apply(AllChem.MolFromSmiles)\n",
    "        df_compounds['fingerprint'] = df_compounds['rdkit_mol'].apply(lambda mol: AllChem.GetMorganFingerprintAsBitVect(mol, 2) if mol is not None else None)\n",
    "\n",
    "    # Alternatively, use RDKFingerprint\n",
    "    # df_compounds['fingerprint'] = df_compounds['rdkit_mol'].apply(lambda mol: Chem.RDKFingerprint(mol) if mol is not None else None)  \n",
    "        print(\"RDKit molecules and fingerprints generated.\")\n",
    "\n",
    "# Update the .pkl file with the new columns\n",
    "if not df_compounds.empty:\n",
    "    pkl_file = f\"compounds_MW{mw_range[0]}-{mw_range[1]}_LogP{logp_range[0]}-{logp_range[1]}.pkl\"\n",
    "    df_compounds.to_pickle(pkl_file)\n",
    "    print(f\"Updated DataFrame with RDKit molecules and fingerprints saved to {pkl_file}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7f7573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the morgan fingerprints for tSNE visualization and k-means clustering\n",
    "\n",
    "if not df_compounds.empty:\n",
    "    print(\"\\nPerforming tSNE and k-means clustering...\")\n",
    "    # Extract fingerprints and convert to numpy array\n",
    "    fps = [fp for fp in df_compounds['fingerprint'] if fp is not None]\n",
    "    fps_array = np.array([np.array(fp) for fp in fps])\n",
    "\n",
    "    # Perform tSNE\n",
    "    tsne = TSNE(n_components=2, random_state=42)\n",
    "    tsne_results = tsne.fit_transform(fps_array)\n",
    "\n",
    "    # Perform k-means clustering\n",
    "    n_clusters = 20\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    cluster_labels = kmeans.fit_predict(fps_array)\n",
    "\n",
    "    # Add tSNE results and cluster labels to DataFrame\n",
    "    df_compounds = df_compounds[df_compounds['fingerprint'].notnull()].copy()\n",
    "    df_compounds['tsne_x'] = tsne_results[:, 0]\n",
    "    df_compounds['tsne_y'] = tsne_results[:, 1]\n",
    "    df_compounds['cluster'] = cluster_labels\n",
    "\n",
    "    # Calculate cluster statistics to identify tight clusters\n",
    "    from scipy.spatial.distance import cdist\n",
    "    \n",
    "    cluster_stats = []\n",
    "    for cluster_id in range(n_clusters):\n",
    "        cluster_mask = df_compounds['cluster'] == cluster_id\n",
    "        cluster_points = fps_array[cluster_mask]\n",
    "        \n",
    "        if len(cluster_points) > 1:\n",
    "            # Calculate cluster center (centroid)\n",
    "            cluster_center = kmeans.cluster_centers_[cluster_id]\n",
    "            \n",
    "            # Calculate distances from each point to cluster center\n",
    "            distances = cdist([cluster_center], cluster_points, metric='euclidean')[0]\n",
    "            \n",
    "            # Calculate cluster tightness metrics\n",
    "            mean_distance = np.mean(distances)\n",
    "            std_distance = np.std(distances)\n",
    "            max_distance = np.max(distances)\n",
    "            \n",
    "            cluster_stats.append({\n",
    "                'cluster_id': cluster_id,\n",
    "                'size': len(cluster_points),\n",
    "                'mean_distance': mean_distance,\n",
    "                'std_distance': std_distance,\n",
    "                'max_distance': max_distance,\n",
    "                'tightness_score': mean_distance + std_distance  # Lower is tighter\n",
    "            })\n",
    "    \n",
    "    cluster_stats_df = pd.DataFrame(cluster_stats)\n",
    "    \n",
    "    # Define threshold for \"tight\" clusters (you can adjust this)\n",
    "    tightness_threshold = cluster_stats_df['tightness_score'].quantile(0.3)  # Top 30% tightest clusters\n",
    "    tight_clusters = cluster_stats_df[cluster_stats_df['tightness_score'] <= tightness_threshold]\n",
    "    \n",
    "    print(f\"\\nIdentified {len(tight_clusters)} tight clusters out of {n_clusters} total clusters\")\n",
    "    print(\"\\nTight cluster statistics:\")\n",
    "    print(tight_clusters[['cluster_id', 'size', 'mean_distance', 'std_distance']])\n",
    "    \n",
    "    # Select one representative molecule from each tight cluster\n",
    "    representative_molecules = []\n",
    "    tight_cluster_ids = set()\n",
    "    \n",
    "    for _, cluster_info in tight_clusters.iterrows():\n",
    "        cluster_id = int(cluster_info['cluster_id'])  # Convert to int\n",
    "        tight_cluster_ids.add(cluster_id)\n",
    "        \n",
    "        cluster_mask = df_compounds['cluster'] == cluster_id\n",
    "        cluster_compounds = df_compounds[cluster_mask].copy()\n",
    "        cluster_fps = fps_array[cluster_mask]\n",
    "        \n",
    "        # Calculate distance of each molecule to cluster center\n",
    "        cluster_center = kmeans.cluster_centers_[cluster_id]\n",
    "        distances = cdist([cluster_center], cluster_fps, metric='euclidean')[0]\n",
    "        \n",
    "        # Add distances to dataframe\n",
    "        cluster_compounds['distance_to_center'] = distances\n",
    "        \n",
    "        # Select the molecule closest to center\n",
    "        representative = cluster_compounds.nsmallest(1, 'distance_to_center')\n",
    "        representative_molecules.append(representative)\n",
    "    \n",
    "    # Combine all representative molecules\n",
    "    df_representatives = pd.concat(representative_molecules, ignore_index=True)\n",
    "    \n",
    "    print(f\"\\nSelected {len(df_representatives)} representative molecules from tight clusters\")\n",
    "    \n",
    "    # Get all molecules NOT in tight clusters\n",
    "    df_not_in_tight_clusters = df_compounds[~df_compounds['cluster'].isin(tight_cluster_ids)].copy()\n",
    "    \n",
    "    print(f\"Kept {len(df_not_in_tight_clusters)} molecules not in tight clusters\")\n",
    "    \n",
    "    # Combine representatives with non-tight-cluster molecules\n",
    "    df_diverse = pd.concat([df_representatives, df_not_in_tight_clusters], ignore_index=True)\n",
    "    \n",
    "    print(f\"\\n=== Diversity Selection Summary ===\")\n",
    "    print(f\"Original compounds: {len(df_compounds)}\")\n",
    "    print(f\"Molecules in tight clusters (removed): {len(df_compounds[df_compounds['cluster'].isin(tight_cluster_ids)]) - len(df_representatives)}\")\n",
    "    print(f\"Representatives from tight clusters: {len(df_representatives)}\")\n",
    "    print(f\"Molecules not in tight clusters: {len(df_not_in_tight_clusters)}\")\n",
    "    print(f\"Final diverse set: {len(df_diverse)}\")\n",
    "    \n",
    "    # Plot tSNE results showing what was kept vs removed\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    \n",
    "    # Left plot: Original with tight clusters highlighted\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.scatter(df_compounds['tsne_x'], df_compounds['tsne_y'], \n",
    "                c='lightgrey', alpha=0.3, s=30, label='All compounds')\n",
    "    \n",
    "    # Highlight tight clusters\n",
    "    for cluster_id in tight_cluster_ids:\n",
    "        cluster_mask = df_compounds['cluster'] == cluster_id\n",
    "        plt.scatter(df_compounds[cluster_mask]['tsne_x'], \n",
    "                   df_compounds[cluster_mask]['tsne_y'],\n",
    "                   alpha=0.6, s=50, label=f'Tight cluster {cluster_id}')\n",
    "    \n",
    "    # Mark representative molecules\n",
    "    plt.scatter(df_representatives['tsne_x'], df_representatives['tsne_y'],\n",
    "                c='red', marker='*', s=300, edgecolors='black', linewidths=2,\n",
    "                label='Representatives', zorder=5)\n",
    "    \n",
    "    plt.title(f'Original: {len(df_compounds)} compounds')\n",
    "    plt.xlabel('tSNE X')\n",
    "    plt.ylabel('tSNE Y')\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=8)\n",
    "    \n",
    "    # Right plot: Final diverse set\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.scatter(df_diverse['tsne_x'], df_diverse['tsne_y'], \n",
    "                c='blue', alpha=0.5, s=50, label='Diverse set')\n",
    "    plt.scatter(df_representatives['tsne_x'], df_representatives['tsne_y'],\n",
    "                c='red', marker='*', s=300, edgecolors='black', linewidths=2,\n",
    "                label='Cluster representatives', zorder=5)\n",
    "    \n",
    "    plt.title(f'Diverse Set: {len(df_diverse)} compounds')\n",
    "    plt.xlabel('tSNE X')\n",
    "    plt.ylabel('tSNE Y')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Replace df_compounds with the diverse set\n",
    "    df_compounds = df_diverse.copy()\n",
    "    \n",
    "    # Save the diverse set\n",
    "    output_file = f\"diverse_MW{mw_range[0]}-{mw_range[1]}_LogP{logp_range[0]}-{logp_range[1]}.csv\"\n",
    "    df_compounds.to_csv(output_file, index=False)\n",
    "    \n",
    "    pkl_file = f\"diverse_MW{mw_range[0]}-{mw_range[1]}_LogP{logp_range[0]}-{logp_range[1]}.pkl\"\n",
    "    df_compounds.to_pickle(pkl_file)\n",
    "    \n",
    "    print(f\"\\nDiverse compound set saved to {output_file}\")\n",
    "    print(f\"Diverse compound set saved to {pkl_file}\")\n",
    "    \n",
    "    # Also save just the representatives for reference\n",
    "    repr_output_file = f\"representatives_MW{mw_range[0]}-{mw_range[1]}_LogP{logp_range[0]}-{logp_range[1]}.csv\"\n",
    "    df_representatives.to_csv(repr_output_file, index=False)\n",
    "    print(f\"Cluster representatives saved to {repr_output_file}\")\n",
    "    \n",
    "    # Display sample from diverse set\n",
    "    print(\"\\n=== Sample Diverse Compounds ===\")\n",
    "    print(df_compounds[['chembl_id', 'canonical_smiles', 'cluster']].head(10))\n",
    "\n",
    "# Save the final diverse set as a CSV file:\n",
    "    output_file = f\"diverse_MW{mw_range[0]}-{mw_range[1]}_LogP{logp_range[0]}-{logp_range[1]}.csv\"\n",
    "    df_compounds.to_csv(output_file, index=False)\n",
    "    \n",
    "    pkl_file = f\"diverse_MW{mw_range[0]}-{mw_range[1]}_LogP{logp_range[0]}-{logp_range[1]}.pkl\"\n",
    "    df_compounds.to_pickle(pkl_file)\n",
    "    \n",
    "    print(f\"\\nDiverse compound set saved to {output_file}\")\n",
    "    print(f\"Diverse compound set saved to {pkl_file}\")\n",
    "    \n",
    "    # Also save just the representatives for reference\n",
    "    repr_output_file = f\"representatives_MW{mw_range[0]}-{mw_range[1]}_LogP{logp_range[0]}-{logp_range[1]}.csv\"\n",
    "    df_representatives.to_csv(repr_output_file, index=False)\n",
    "    print(f\"Cluster representatives saved to {repr_output_file}\")\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cda9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Create a random subset of the diverse set\n",
    "\n",
    "if not df_compounds.empty:\n",
    "    if len(df_compounds) > random_subset_amount:\n",
    "        print(f\"\\nCreating random subset of {random_subset_amount} molecules from {len(df_compounds)} diverse compounds...\")\n",
    "        df_random_subset = df_compounds.sample(n=random_subset_amount, random_state=42)\n",
    "        \n",
    "        # Save the random subset\n",
    "        output_file = f\"random{random_subset_amount}_MW{mw_range[0]}-{mw_range[1]}_LogP{logp_range[0]}-{logp_range[1]}.csv\"\n",
    "        df_random_subset.to_csv(output_file, index=False)\n",
    "        \n",
    "        pkl_file = f\"random{random_subset_amount}_MW{mw_range[0]}-{mw_range[1]}_LogP{logp_range[0]}-{logp_range[1]}.pkl\"\n",
    "        df_random_subset.to_pickle(pkl_file)\n",
    "        \n",
    "        print(f\"Random subset saved to {output_file}\")\n",
    "        print(f\"Random subset saved to {pkl_file}\")\n",
    "        \n",
    "        # Display sample\n",
    "        print(\"\\n=== Sample Random Subset ===\")\n",
    "        print(df_random_subset[['chembl_id', 'canonical_smiles', 'molecular_weight', 'alogp']].head(10))\n",
    "    else:\n",
    "        print(f\"\\nDataFrame has {len(df_compounds)} molecules, which is less than or equal to requested subset size of {random_subset_amount}\")\n",
    "        print(\"Skipping random subset creation.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chEMBL_tools",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
